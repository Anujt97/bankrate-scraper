name: Scrapy Spider Runner

on:
  workflow_dispatch:
  schedule:
    - cron: '30 3 * * *'  # Runs daily at 9:00 AM IST

permissions:
  contents: write  # ‚úÖ Grant write access to the repo

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}  # Uses the default GitHub token

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run Scrapy spider
      run: scrapy crawl table_spider

    - name: üì§ Upload log file
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scrapy-log
        path: scrapy_log.log

    - name: Commit and push updated files
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git add output.csv output.json
        git commit -m "‚¨ÜÔ∏è Update output files with new scraped data [CI skip]" || echo "No changes to commit"
        git push
